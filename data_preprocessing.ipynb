{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "data_preprocessing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwgB1WdM4C3_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32aea2fe-5ba7-4427-b198-5c7e242dda20"
      },
      "source": [
        "# Mount Google Drive to the Colab VM.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Specify working directory.\n",
        "FOLDERNAME = 'cs231n/project/'\n",
        "%cd /content/drive/My\\ Drive/$FOLDERNAME\n",
        "\n",
        "# Ensure that the Python interpreter of the Colab VM can load python files from\n",
        "# within it.\n",
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/{}'.format(FOLDERNAME))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/My Drive/cs231n/project\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKlouTNl_nSJ"
      },
      "source": [
        "## Create videos dataframe\n",
        "Download \n",
        "BII Sneeze-Cough Human Action Video Dataset at https://web.bii.a-star.edu.sg/~chengli/FluRecognition/videos/biisc.zip, unzip it, and save the `videos` folder under directory `cs231n/project/dataset/videos`.\n",
        "\n",
        "Video File Naming Convention:\n",
        "\n",
        "\\{subject id: 4 char\\}_{gender: 1 char}_\\{action: 4 char\\}_\\{stand or walk: 3 char\\}_\\{pose: 3 char\\}[_HF].avi\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jyoqLXma86SZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "e83cdcae-7f4a-49b0-e43f-b6215db0f519"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "video_path = 'dataset/videos/'\n",
        "videos = os.listdir(video_path)\n",
        "subjects = []\n",
        "actions =[]\n",
        "\n",
        "for vid in videos:\n",
        "  # Read index.\n",
        "  subjects.append(vid[:4])\n",
        "  # Read actions\n",
        "  actions.append(vid.split('_')[2])\n",
        "\n",
        "# Convert actions to 1 = flu sym, 0 = no flu sym.\n",
        "mapping = {\n",
        "    'CALL': 0,\n",
        "    'COUG': 1,\n",
        "    'DRIN': 0,\n",
        "    'SCRA': 0,\n",
        "    'SNEE': 1,\n",
        "    'STRE': 0,\n",
        "    'WAVE': 0,\n",
        "    'WIPE': 0,\n",
        "}\n",
        "labels = [mapping[x] for x in actions]    \n",
        "\n",
        "df_videos = pd.DataFrame({\n",
        "    'video_subject': subjects,\n",
        "    'video_name': videos,\n",
        "    'action': actions,\n",
        "    'label': labels\n",
        "    \n",
        "})\n",
        "df_videos.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>video_subject</th>\n",
              "      <th>video_name</th>\n",
              "      <th>action</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>S018</td>\n",
              "      <td>S018_M_WAVE_WLK_LFT_HF.avi</td>\n",
              "      <td>WAVE</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>S012</td>\n",
              "      <td>S012_M_CALL_WLK_LFT.avi</td>\n",
              "      <td>CALL</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>S015</td>\n",
              "      <td>S015_M_CALL_STD_LFT_HF.avi</td>\n",
              "      <td>CALL</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>S016</td>\n",
              "      <td>S016_F_SNEE_STD_RGT_HF.avi</td>\n",
              "      <td>SNEE</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>S018</td>\n",
              "      <td>S018_M_SCRA_STD_LFT_HF.avi</td>\n",
              "      <td>SCRA</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  video_subject                  video_name action  label\n",
              "0          S018  S018_M_WAVE_WLK_LFT_HF.avi   WAVE      0\n",
              "1          S012     S012_M_CALL_WLK_LFT.avi   CALL      0\n",
              "2          S015  S015_M_CALL_STD_LFT_HF.avi   CALL      0\n",
              "3          S016  S016_F_SNEE_STD_RGT_HF.avi   SNEE      1\n",
              "4          S018  S018_M_SCRA_STD_LFT_HF.avi   SCRA      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEQcMNP6d3NB"
      },
      "source": [
        "# Shuffle df_videos.\n",
        "df_videos = df_videos.sample(frac=1, random_state=42).reset_index(drop=True)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "daKk1JvPTrXj"
      },
      "source": [
        "## Create Train/Test datasets\n",
        "\n",
        "From the paper authors: \"In our current experiments, the videos from subjects S002, S003, S004, S005, S006 are used for testing and the rest are used for training.\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0i6ZH_u-cm4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d6ec00f-7839-4ada-a8d6-555aa4ede121"
      },
      "source": [
        "df_videos_train = df_videos.loc[~df_videos['video_subject'].isin(\n",
        "    ['S002','S003', 'S004', 'S005', 'S006'])].reset_index()\n",
        "df_videos_test  = df_videos.loc[df_videos['video_subject'].isin(\n",
        "    ['S002','S003', 'S004', 'S005', 'S006'])].reset_index()\n",
        "print(df_videos_train.groupby('label').count())\n",
        "print(df_videos_test.groupby('label').count())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       index  video_subject  video_name  action\n",
            "label                                          \n",
            "0       1080           1080        1080    1080\n",
            "1        360            360         360     360\n",
            "       index  video_subject  video_name  action\n",
            "label                                          \n",
            "0        360            360         360     360\n",
            "1        120            120         120     120\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bUmZ-8ncT0SH"
      },
      "source": [
        "## Create folders for Train & Test frames"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPd9Sx05-pjj"
      },
      "source": [
        "frames_path = 'dataset/frames/'\n",
        "train_frames_path = os.path.join(frames_path, 'train')\n",
        "test_frames_path = os.path.join(frames_path, 'test')\n",
        "try:\n",
        "    os.mkdir(frames_path)\n",
        "except FileExistsError as ae:\n",
        "    print('dataset/frames already created')\n",
        "try:\n",
        "    os.mkdir(train_frames_path)\n",
        "except FileExistsError as ae:\n",
        "    print('dataset/frames/train already created')\n",
        "try:\n",
        "    os.mkdir(test_frames_path)\n",
        "except FileExistsError as ae:\n",
        "    print('dataset/frames/test already created')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44RqmWclPVhT"
      },
      "source": [
        "### Extract frames from videos\n",
        "\n",
        "We extract two frames from each second of the video and save the frames as images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cfTGewhGwq4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf8f4f15-0423-49a4-bb67-5f2a0ad31748"
      },
      "source": [
        "# Read the video files, extract frames from each corresponding video and put\n",
        "# them in the corresponding train/test folder.\n",
        "import cv2\n",
        "\n",
        "def extract_frames(df, folder_name):\n",
        "    for _, row in df.iterrows():\n",
        "        _, video_subject, video_name, action, label = row\n",
        "        video_read_path = os.path.join(video_path, video_name)\n",
        "        try:\n",
        "          os.mkdir(os.path.join(os.path.join(frames_path, folder_name),\n",
        "                                video_name.split(\".\")[0]))\n",
        "          \n",
        "          train_write_file=os.path.join(os.path.join(frames_path, folder_name),\n",
        "                                    video_name.split(\".\")[0])\n",
        "          cap=cv2.VideoCapture(video_read_path)\n",
        "          cap.set(cv2.CAP_PROP_FPS, 20)\n",
        "          frame_rate=int(cap.get(5))\n",
        "          \n",
        "          count=0\n",
        "          while(cap.isOpened()):\n",
        "              frame_id = cap.get(1)\n",
        "              ret, frame = cap.read()\n",
        "              if (ret != True):\n",
        "                  break\n",
        "              # Extract 2 frames from each second.\n",
        "              if (2 * frame_id % frame_rate == 0):\n",
        "                  filename =\"frame%d.jpg\" % count; count+=1\n",
        "                  frame_grey=cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "                  cv2.imwrite(os.path.join(train_write_file,filename), frame_grey)\n",
        "          cap.release()\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    return print(\"All frames written in the \"+folder_name+\" folder\")\n",
        "\n",
        "extract_frames(df_videos_train, 'train')\n",
        "extract_frames(df_videos_test, 'test')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All frames written in the train folder\n",
            "All frames written in the test folder\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0Mt6rrWG7Cw"
      },
      "source": [
        "# See how many frames are captured for each video.\n",
        "train_path='/content/drive/My Drive/cs231n/project/dataset/frames/train/'\n",
        "test_path='/content/drive/My Drive/cs231n/project/dataset/frames/test/'\n",
        "\n",
        "vid_file_name=df_videos_train.video_name[0].split('.')[0]\n",
        "\n",
        "train_frames=[]\n",
        "for i in range(len(df_videos_train.video_name)):\n",
        "    vid_file_name=df_videos_train.video_name[i].split('.')[0]\n",
        "    train_frames.append(len(os.listdir(os.path.join(train_path, vid_file_name))))\n",
        "\n",
        "test_frames=[]\n",
        "for i in range(len(df_videos_test.video_name)):\n",
        "    vid_file_name=df_videos_test.video_name[i].split('.')[0]\n",
        "    test_frames.append(len(os.listdir(os.path.join(test_path,vid_file_name))))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bie8175bTPTt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "outputId": "da7ba0d4-824a-40e9-f555-f42530b35741"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.hist(train_frames)\n",
        "plt.show()\n",
        "\n",
        "plt.hist(test_frames)\n",
        "plt.show()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAARo0lEQVR4nO3dfawld13H8fdHloI8aFv2Wstu4xYtmGJEmmstIqRaAqUlbDWEtEFdockGLQiCwgIJ9R+SAiriU81C1y6mKVQE2vAglAo2JrZ4W/vcQpfS0t1suxfLg4oBFr7+caZ6vD33cc459+6v71dyc2Z+85sz350797Nzf3dmTqoKSVJbfmi9C5AkjZ/hLkkNMtwlqUGGuyQ1yHCXpAZtWu8CADZv3lzbtm1b7zIk6Yhyww03fK2qZkYt2xDhvm3bNubm5ta7DEk6oiS5b7FlDstIUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGrRsuCfZk+RQktsWtL82yV1Jbk/yrqH2tyTZl+SLSV40iaIlSUtbyR2qlwJ/AXzg4YYkvwxsB55VVd9J8mNd+8nAucAzgacCn03y9Kr6/rgL1/rYtusT67Ldey86e122Kx2plj1zr6prgYcWNP82cFFVfafrc6hr3w58sKq+U1VfAfYBp46xXknSCqx1zP3pwPOSXJ/kn5L8fNe+Bbh/qN/+ru0RkuxMMpdkbn5+fo1lSJJGWWu4bwKOBU4D/gC4IklW8wZVtbuqZqtqdmZm5EPNJElrtNZw3w98pAa+APwA2AwcAE4Y6re1a5MkTdFaw/1jwC8DJHk6cBTwNeAq4Nwkj0tyInAS8IVxFCpJWrllr5ZJcjlwOrA5yX7gQmAPsKe7PPK7wI6qKuD2JFcAdwCHgQu8UkaSpm/ZcK+q8xZZ9OuL9H8H8I4+RUmS+vEOVUlqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWrQsuGeZE+SQ91H6i1c9sYklWRzN58kf5ZkX5JbkpwyiaIlSUtbyZn7pcCZCxuTnAC8EPjqUPOLGXwo9knATuDi/iVKklZr2XCvqmuBh0Yseg/wJqCG2rYDH6iB64Cjkxw/lkolSSu2pjH3JNuBA1V184JFW4D7h+b3d22j3mNnkrkkc/Pz82spQ5K0iFWHe5InAG8F3t5nw1W1u6pmq2p2Zmamz1tJkhbYtIZ1fhI4Ebg5CcBW4MYkpwIHgBOG+m7t2iRJU7TqM/equrWqfqyqtlXVNgZDL6dU1QPAVcBvdlfNnAZ8s6oOjrdkSdJyVnIp5OXAvwDPSLI/yflLdP8kcA+wD3gf8DtjqVKStCrLDstU1XnLLN82NF3ABf3LkiT14R2qktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGreSTmPYkOZTktqG2dye5K8ktST6a5OihZW9Jsi/JF5O8aFKFS5IWt5Iz90uBMxe0XQ38TFX9LPAl4C0ASU4GzgWe2a3zV0keM7ZqJUkrsmy4V9W1wEML2j5TVYe72euArd30duCDVfWdqvoKg89SPXWM9UqSVmAcY+6vAj7VTW8B7h9atr9re4QkO5PMJZmbn58fQxmSpIf1CvckbwMOA5etdt2q2l1Vs1U1OzMz06cMSdICm9a6YpLfAl4CnFFV1TUfAE4Y6ra1a5MkTdGaztyTnAm8CXhpVX17aNFVwLlJHpfkROAk4Av9y5QkrcayZ+5JLgdOBzYn2Q9cyODqmMcBVycBuK6qXl1Vtye5AriDwXDNBVX1/UkVL0kabdlwr6rzRjRfskT/dwDv6FOUJKkf71CVpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBi0b7kn2JDmU5LahtmOTXJ3k7u71mK49Sf4syb4ktyQ5ZZLFS5JGW8mZ+6XAmQvadgHXVNVJwDXdPMCLGXwo9knATuDi8ZQpSVqNZcO9qq4FHlrQvB3Y203vBc4Zav9ADVwHHJ3k+HEVK0lambWOuR9XVQe76QeA47rpLcD9Q/32d22PkGRnkrkkc/Pz82ssQ5I0Su8/qFZVAbWG9XZX1WxVzc7MzPQtQ5I0ZK3h/uDDwy3d66Gu/QBwwlC/rV2bJGmK1hruVwE7uukdwJVD7b/ZXTVzGvDNoeEbSdKUbFquQ5LLgdOBzUn2AxcCFwFXJDkfuA94edf9k8BZwD7g28ArJ1CzJGkZy4Z7VZ23yKIzRvQt4IK+RWlp23Z9Yr1LkLTBeYeqJDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBvcI9ye8luT3JbUkuT/L4JCcmuT7JviQfSnLUuIqVJK3Msp/EtJgkW4DfBU6uqv9OcgVwLoOP2XtPVX0wyV8D5wMXj6VaPWqt56dP3XvR2eu2bWmt+g7LbAJ+OMkm4AnAQeBXgA93y/cC5/TchiRpldYc7lV1APgj4KsMQv2bwA3AN6rqcNdtP7Clb5GSpNVZc7gnOQbYDpwIPBV4InDmKtbfmWQuydz8/Pxay5AkjdBnWOYFwFeqar6qvgd8BHgucHQ3TAOwFTgwauWq2l1Vs1U1OzMz06MMSdJCfcL9q8BpSZ6QJMAZwB3A54CXdX12AFf2K1GStFp9xtyvZ/CH0xuBW7v32g28GXhDkn3AU4BLxlCnJGkV1nwpJEBVXQhcuKD5HuDUPu8rSerHO1QlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqUK/nuUuPBtt2fWJdtnvvRWevy3bVBs/cJalBvcI9ydFJPpzkriR3JnlOkmOTXJ3k7u71mHEVK0lamb5n7u8F/qGqfhp4FnAnsAu4pqpOAq7p5iVJU7TmcE/yo8Dz6T4Au6q+W1XfALYDe7tue4Fz+hYpSVqdPmfuJwLzwN8k+bck70/yROC4qjrY9XkAOG7Uykl2JplLMjc/P9+jDEnSQn3CfRNwCnBxVT0b+C8WDMFUVQE1auWq2l1Vs1U1OzMz06MMSdJCfcJ9P7C/qq7v5j/MIOwfTHI8QPd6qF+JkqTVWnO4V9UDwP1JntE1nQHcAVwF7OjadgBX9qpQkrRqfW9iei1wWZKjgHuAVzL4D+OKJOcD9wEv77kNSdIq9Qr3qroJmB2x6Iw+7ytJ6sc7VCWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBvcM9yWOS/FuSj3fzJya5Psm+JB/qPoJPkjRF4zhzfx1w59D8O4H3VNVPAV8Hzh/DNiRJq9Ar3JNsBc4G3t/NB/gV4MNdl73AOX22IUlavb5n7n8KvAn4QTf/FOAbVXW4m98PbBm1YpKdSeaSzM3Pz/csQ5I0bM3hnuQlwKGqumEt61fV7qqararZmZmZtZYhSRphU491nwu8NMlZwOOBHwHeCxydZFN39r4VONC/TEnSaqz5zL2q3lJVW6tqG3Au8I9V9Qrgc8DLum47gCt7VylJWpVJXOf+ZuANSfYxGIO/ZALbkCQtoc+wzP+qqs8Dn++m7wFOHcf7SpLWxjtUJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktSgsTw47NFq265PrHcJkjSSZ+6S1CDDXZIaZLhLUoP6fED2CUk+l+SOJLcneV3XfmySq5Pc3b0eM75yJUkr0efM/TDwxqo6GTgNuCDJycAu4JqqOgm4ppuXJE1Rnw/IPlhVN3bT/wHcCWwBtgN7u257gXP6FilJWp2xjLkn2QY8G7geOK6qDnaLHgCOW2SdnUnmkszNz8+PowxJUqd3uCd5EvD3wOur6lvDy6qqgBq1XlXtrqrZqpqdmZnpW4YkaUivcE/yWAbBfllVfaRrfjDJ8d3y44FD/UqUJK1Wn6tlAlwC3FlVfzK06CpgRze9A7hy7eVJktaiz+MHngv8BnBrkpu6trcCFwFXJDkfuA94eb8SJUmrteZwr6p/BrLI4jPW+r6SpP68Q1WSGmS4S1KDjvhH/vrYXUl6JM/cJalBR/yZu9Sq9fqt9N6Lzl6X7cKj8988KZ65S1KDDHdJapDDMpL+Hy9SaINn7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1KCJ3aGa5EzgvcBjgPdX1UWT2pYk9bGed+VO6qFlEzlzT/IY4C+BFwMnA+clOXkS25IkPdKkhmVOBfZV1T1V9V3gg8D2CW1LkrTApIZltgD3D83vB35huEOSncDObvY/k3xxQrUAbAa+NsH3HxfrHL8jpVbrHL8jota8s1edP7HYgnV7KmRV7QZ2T2NbSeaqanYa2+rDOsfvSKnVOsfvSKl1UnVOaljmAHDC0PzWrk2SNAWTCvd/BU5KcmKSo4BzgasmtC1J0gITGZapqsNJXgN8msGlkHuq6vZJbGuFpjL8MwbWOX5HSq3WOX5HSq0TqTNVNYn3lSStI+9QlaQGGe6S1KBmwj3JM5LcNPT1rSSvX9Dn9CTfHOrz9inVtifJoSS3DbUdm+TqJHd3r8cssu6Ors/dSXasQ53vTnJXkluSfDTJ0Yuse2+SW7v9OjfJOpeo9Q+THBj6/p61yLpnJvlikn1Jdq1DnR8aqvHeJDctsu7U9mmSE5J8LskdSW5P8rqufUMdp0vUuaGO0yXqnN4xWlXNfTH4I+4DwE8saD8d+Pg61PN84BTgtqG2dwG7uuldwDtHrHcscE/3ekw3fcyU63whsKmbfueoOrtl9wKb13mf/iHw+ys4Nr4MPA04CrgZOHmadS5Y/sfA29d7nwLHA6d0008GvsTg0SEb6jhdos4NdZwuUefUjtFmztwXOAP4clXdt96FAFTVtcBDC5q3A3u76b3AOSNWfRFwdVU9VFVfB64GzpxmnVX1mao63M1ex+CehXW3yD5diak+GmOpOpMEeDlw+aS2v1JVdbCqbuym/wO4k8Gd5hvqOF2szo12nC6xP1diLMdoq+F+Lov/wDwnyc1JPpXkmdMsaoHjqupgN/0AcNyIPqMe47DSA2QSXgV8apFlBXwmyQ3doyXWy2u6X833LDKEsJH26fOAB6vq7kWWr8s+TbINeDZwPRv4OF1Q57ANdZyOqHMqx2hz4d7dNPVS4O9GLL6RwVDNs4A/Bz42zdoWU4PfxTb0NalJ3gYcBi5bpMsvVdUpDJ4EekGS50+tuP9zMfCTwM8BBxkMeWxk57H0WfvU92mSJwF/D7y+qr41vGwjHaeL1bnRjtMRdU7tGG0u3Bl8026sqgcXLqiqb1XVf3bTnwQem2TztAvsPJjkeIDu9dCIPhviMQ5Jfgt4CfCK7gf8EarqQPd6CPgog18tp6qqHqyq71fVD4D3LVLDRtmnm4BfAz60WJ9p79Mkj2UQRJdV1Ue65g13nC5S54Y7TkfVOc1jtMVwX/RsKMmPd+OcJDmVwb//36dY27CrgIevKtgBXDmiz6eBFyY5pvv17YVd29Rk8KErbwJeWlXfXqTPE5M8+eFpBnXeNqrvJD0cQp1fXaSGjfJojBcAd1XV/lELp71Pu5+LS4A7q+pPhhZtqON0sTo32nG6RJ3TO0Yn/VfjaX4BT2QQ1j861PZq4NXd9GuA2xn89fk64BenVNflDH4F+x6D8bPzgacA1wB3A58Fju36zjL45KqH130VsK/7euU61LmPwfjfTd3XX3d9nwp8spt+WrdPb+7279vWaZ/+LXArcEv3w3D8wlq7+bMYXL3w5UnXOqrOrv3Sh4/Lob7rtk+BX2Iw5HLL0Pf6rI12nC5R54Y6Tpeoc2rHqI8fkKQGtTgsI0mPeoa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJatD/AE1JySr9AeJ4AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxVYYtgxLPrw"
      },
      "source": [
        "\n",
        "## Making sure that each video has at least 20 frames\n",
        "\n",
        "Some videos are of length <10 secs, so the frames captured from them are less than 20. We will generate extra frames by creating copies of the last frame and put them at the end. This is to make sure that we have at least 20 frames in each video."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCIT4UAkIQOd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b2f7fb1-c02b-49b4-b7aa-5236c1e761fb"
      },
      "source": [
        "import shutil\n",
        "\n",
        "def extract_frames(dataset, dir_path):\n",
        "    for i in range(len(dataset.video_name)):\n",
        "        vid_namu = dataset.video_name[i]\n",
        "        vid_path = os.path.join(dir_path,vid_namu.split(\".\")[0])\n",
        "        len_frame = len(os.listdir(vid_path))\n",
        "        j = 20 - len(os.listdir(vid_path))\n",
        "        if j > 0:\n",
        "            list_frames = os.listdir(vid_path)\n",
        "            c = 0\n",
        "            for k in range(j):\n",
        "                list_frames=os.listdir(vid_path)\n",
        "                frame=os.path.join(vid_path, list_frames[c])\n",
        "                countu=k+len_frame\n",
        "                new_frame=\"frame%d.jpg\" % countu\n",
        "                shutil.copy2(frame,os.path.join(vid_path,new_frame))\n",
        "                c+=1\n",
        "        else:\n",
        "            pass\n",
        "    return print(\"Frame Generation Done!\")\n",
        "    \n",
        "train_path='/content/drive/My Drive/cs231n/project/dataset/frames/train/'\n",
        "test_path='/content/drive/My Drive/cs231n/project/dataset/frames/test/'\n",
        "\n",
        "extract_frames(df_videos_train, train_path)\n",
        "extract_frames(df_videos_test, test_path)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Frame Generation Done!\n",
            "Frame Generation Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7FPFIfTMcuhO"
      },
      "source": [
        "## Split training and validation datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FK7IqdPncu1b"
      },
      "source": [
        "train_ratio = 0.70\n",
        "\n",
        "label_1_dat = df_videos_train.loc[df_videos_train[\"label\"]==1,]\n",
        "label_0_dat = df_videos_train.loc[df_videos_train[\"label\"]==0,]\n",
        "\n",
        "train_len_label1 = int(len(label_1_dat)*train_ratio)\n",
        "train_len_label0 = int(len(label_0_dat)*train_ratio)\n",
        "\n",
        "train_dat_label1 = label_1_dat.iloc[:train_len_label1,]\n",
        "train_dat_label0 = label_0_dat.iloc[:train_len_label0,]\n",
        "\n",
        "val_dat_label1 = label_1_dat.iloc[train_len_label1:,]\n",
        "val_dat_label0 = label_0_dat.iloc[train_len_label0:,]\n",
        "\n",
        "train_dat = train_dat_label1.append(train_dat_label0, ignore_index=True)\n",
        "val_dat = val_dat_label1.append(val_dat_label0, ignore_index=True)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrF2z1BXcw5j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9524e51-8d9f-4a37-a806-6ccd560b9c35"
      },
      "source": [
        "print(train_dat.groupby('action')['index'].count())\n",
        "print(val_dat.groupby('action')['index'].count())"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "action\n",
            "CALL    125\n",
            "COUG    121\n",
            "DRIN    120\n",
            "SCRA    129\n",
            "SNEE    130\n",
            "STRE    133\n",
            "WAVE    121\n",
            "WIPE    128\n",
            "Name: index, dtype: int64\n",
            "action\n",
            "CALL    55\n",
            "COUG    59\n",
            "DRIN    60\n",
            "SCRA    51\n",
            "SNEE    50\n",
            "STRE    47\n",
            "WAVE    59\n",
            "WIPE    52\n",
            "Name: index, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9hEwBmIe_wl"
      },
      "source": [
        "## Create final datasets\n",
        "\n",
        "Function below extracts the first 20 frames for each video, resize each frame into (250,250) image and convert it into greyscale image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5f-auioTeiKx"
      },
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "def create_final_dataset(dataset, input_path, output_path):\n",
        "    frames = []\n",
        "    for i in np.arange(len(dataset)):\n",
        "        if i % 100 == 0: print(f'Progress: {i} / {len(dataset)}')\n",
        "        vid_name = dataset.video_name[i].split(\".\")[0]\n",
        "        vid_dir_path = os.path.join(input_path, vid_name)\n",
        "        frames_to_select = []\n",
        "        for l in np.arange(0,20):\n",
        "            frames_to_select.append('frame%d.jpg' % l)\n",
        "        vid_data=[]\n",
        "        for frame in frames_to_select:\n",
        "            image = Image.open(os.path.join(vid_dir_path,frame))\n",
        "            image = image.resize((250, 250), Image.ANTIALIAS) \n",
        "            datu = np.asarray(image)\n",
        "            normu_dat = datu/255\n",
        "            vid_data.append(normu_dat)\n",
        "        vid_data = np.array(vid_data)\n",
        "        frames.append(vid_data)\n",
        "    dataset_new = np.array(frames)\n",
        "    dataset_new = dataset_new.reshape((dataset_new.shape[0],20,250,250,1))\n",
        "    labels = np.array(dataset.label)\n",
        "    return dataset_new, labels"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOI7BmG5a9aq"
      },
      "source": [
        "# Output directory.\n",
        "output_path = \"/content/drive/My Drive/cs231n/project/dataset/shaped_data/\"\n",
        "\n",
        "# Save final dataset.\n",
        "try:\n",
        "    os.mkdir(output_path)\n",
        "except FileExistsError:\n",
        "    pass"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "forBwIO5V7tW"
      },
      "source": [
        "# Training dataset.\n",
        "input_path='/content/drive/My Drive/cs231n/project/dataset/frames/train/'\n",
        "dataset_new, labels = create_final_dataset(train_dat, input_path, output_path)\n",
        "np.save(os.path.join(output_path, \"train_data\"), dataset_new)\n",
        "np.save(os.path.join(output_path, \"train_labels\"), labels)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWSsXY5cV9nV"
      },
      "source": [
        "# Validation dataset.\n",
        "input_path='/content/drive/My Drive/cs231n/project/dataset/frames/train/'\n",
        "dataset_new, labels = create_final_dataset(val_dat, input_path, output_path)\n",
        "np.save(os.path.join(output_path, \"val_data\"), dataset_new)\n",
        "np.save(os.path.join(output_path, \"val_labels\"), labels)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFq-iCMwf4F7"
      },
      "source": [
        "# Test dataset.\n",
        "input_path='/content/drive/My Drive/cs231n/project/dataset/frames/test/'\n",
        "dataset_new, labels = create_final_dataset(df_videos_test, input_path, output_path)\n",
        "np.save(os.path.join(output_path, \"test_data\"), dataset_new)\n",
        "np.save(os.path.join(output_path, \"test_labels\"), labels)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzVjiY0H9QpO"
      },
      "source": [
        "# To load dataset:\n",
        "# train_dataset_new = np.load('/content/drive/My Drive/cs231n/project/dataset/shaped_data/train_data.npy')\n",
        "# val_dataset_new = np.load('/content/drive/My Drive/cs231n/project/dataset/shaped_data/val_data.npy')\n",
        "# test_dataset_new = np.load('/content/drive/My Drive/cs231n/project/dataset/shaped_data/test_data.npy')\n",
        "# train_labels = np.load('/content/drive/My Drive/cs231n/project/dataset/shaped_data/train_labels.npy')\n",
        "# val_labels = np.load('/content/drive/My Drive/cs231n/project/dataset/shaped_data/val_labels.npy')\n",
        "# test_labels = np.load('/content/drive/My Drive/cs231n/project/dataset/shaped_data/test_labels.npy')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}